{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Code for accessing servers to capture video"
      ],
      "metadata": {
        "id": "CuBTH2CvM0ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript,HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        " \n",
        "def record_video(filename):\n",
        "  js=Javascript(\"\"\"\n",
        "    async function recordVideo() {\n",
        "      const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      const stopCapture = document.createElement(\"button\");\n",
        "       \n",
        "      capture.textContent = \"Start Recording\";\n",
        "      capture.style.background = \"orange\";\n",
        "      capture.style.color = \"white\";\n",
        " \n",
        "      stopCapture.textContent = \"Stop Recording\";\n",
        "      stopCapture.style.background = \"red\";\n",
        "      stopCapture.style.color = \"white\";\n",
        "      div.appendChild(capture);\n",
        " \n",
        "      const video = document.createElement('video');\n",
        "      const recordingVid = document.createElement(\"video\");\n",
        "      video.style.display = 'block';\n",
        " \n",
        "      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n",
        "     \n",
        "      let recorder = new MediaRecorder(stream, options);\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        " \n",
        "      video.srcObject = stream;\n",
        "      video.muted = true;\n",
        " \n",
        "      await video.play();\n",
        " \n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        " \n",
        "      await new Promise((resolve) => {\n",
        "        capture.onclick = resolve;\n",
        "      });\n",
        "      recorder.start();\n",
        "      capture.replaceWith(stopCapture);\n",
        " \n",
        "      await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "      recorder.stop();\n",
        "      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "      let arrBuff = await recData.data.arrayBuffer();\n",
        "       \n",
        "      // stop the stream and remove the video element\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        " \n",
        "      let binaryString = \"\";\n",
        "      let bytes = new Uint8Array(arrBuff);\n",
        "      bytes.forEach((byte) => {\n",
        "        binaryString += String.fromCharCode(byte);\n",
        "      })\n",
        "    return btoa(binaryString);\n",
        "    }\n",
        "  \"\"\")\n",
        "  try:\n",
        "    display(js)\n",
        "    data=eval_js('recordVideo({})')\n",
        "    binary=b64decode(data)\n",
        "    with open(filename,\"wb\") as video_file:\n",
        "      video_file.write(binary)\n",
        "    print(f\"Finished recording video at:{filename}\")\n",
        "  except Exception as err:\n",
        "    print(str(err))"
      ],
      "metadata": {
        "id": "3BVsmfhmSJLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing various Pre-trained Classifiers and libraries"
      ],
      "metadata": {
        "id": "3etEhF9tkUkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')"
      ],
      "metadata": {
        "id": "l6noIDpeikr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Code block for detect function"
      ],
      "metadata": {
        "id": "VYedSfNQkj1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will detect our faces, eyes and smiles"
      ],
      "metadata": {
        "id": "70Oeqw_PknGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(gray, frame) :  \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
        "    for (x, y, w, h) in faces:\n",
        "        frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = frame[y:y+h, x:x+w]\n",
        "        \n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 18)\n",
        "        for (ex, ey, ew, eh) in eyes:\n",
        "          cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "        \n",
        "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.1, 22)\n",
        "        for (sx, sy, sw, sh) in smiles:\n",
        "            cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 0, 255), 2)\n",
        "            \n",
        "    return frame"
      ],
      "metadata": {
        "id": "I0lsWeFLPBj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab can not access inbuilt cameras on our computers, hence we will have to create a server API to use Camera as below"
      ],
      "metadata": {
        "id": "fngHr7Cnku0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_capture = \"test.mp4\"\n",
        "record_video(video_capture)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8DU-O63HSV2z",
        "outputId": "4beceefb-39ad-4cb6-9a2d-0f0822f9ea77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function recordVideo() {\n",
              "      const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      const stopCapture = document.createElement(\"button\");\n",
              "       \n",
              "      capture.textContent = \"Start Recording\";\n",
              "      capture.style.background = \"orange\";\n",
              "      capture.style.color = \"white\";\n",
              " \n",
              "      stopCapture.textContent = \"Stop Recording\";\n",
              "      stopCapture.style.background = \"red\";\n",
              "      stopCapture.style.color = \"white\";\n",
              "      div.appendChild(capture);\n",
              " \n",
              "      const video = document.createElement('video');\n",
              "      const recordingVid = document.createElement(\"video\");\n",
              "      video.style.display = 'block';\n",
              " \n",
              "      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n",
              "     \n",
              "      let recorder = new MediaRecorder(stream, options);\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              " \n",
              "      video.srcObject = stream;\n",
              "      video.muted = true;\n",
              " \n",
              "      await video.play();\n",
              " \n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              " \n",
              "      await new Promise((resolve) => {\n",
              "        capture.onclick = resolve;\n",
              "      });\n",
              "      recorder.start();\n",
              "      capture.replaceWith(stopCapture);\n",
              " \n",
              "      await new Promise((resolve) => stopCapture.onclick = resolve);\n",
              "      recorder.stop();\n",
              "      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
              "      let arrBuff = await recData.data.arrayBuffer();\n",
              "       \n",
              "      // stop the stream and remove the video element\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              " \n",
              "      let binaryString = \"\";\n",
              "      let bytes = new Uint8Array(arrBuff);\n",
              "      bytes.forEach((byte) => {\n",
              "        binaryString += String.fromCharCode(byte);\n",
              "      })\n",
              "    return btoa(binaryString);\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished recording video at:test.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_capture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IeQ0e6wdUPFK",
        "outputId": "2cd8eb4b-15eb-4189-9cc8-e15495106834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are accessing your camera. When the parameter is 0, we are accessing an internal camera from your computer. When the parameter is 1, we are accessing an external camera that is plugged on your computer."
      ],
      "metadata": {
        "id": "GzN3lBUgPc0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#video_capture = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "iwqHRzwxM5fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "mIfefbqgWGVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "\n",
        "    # the read() function will return 2 objects, but we are interested only in the latest one, \n",
        "    # that is the last frame from the camera. So we are ignoring the first object _, \n",
        "    # and naming the second as frame, that we will use to feed our detect() function in a second.\n",
        "\n",
        "    source = cv2.VideoCapture(video_capture)\n",
        "    _, frame = source.read()\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    canvas = detect(gray, frame)\n",
        "    \n",
        "    cv2_imshow(canvas)\n",
        "\n",
        "    #This piece of code will stop the program when you press q on the keyboard.\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord('q') :   \n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OkV6XKR9PFVH",
        "outputId": "72d357cc-b24c-4aab-96f8-788afc0249ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_capture.release()  # Turn off the camera\n",
        "cv2.destroyAllWindows() # Close the window"
      ],
      "metadata": {
        "id": "OAXA35KnN3CL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}